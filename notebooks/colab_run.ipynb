{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90308988",
   "metadata": {},
   "source": [
    "# Open in Colab Badge and Runtime Detection\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/piumalnipun9/Inventory-Management-Forecasting-using-Machine-Learning/blob/main/notebooks/colab_run.ipynb)\n",
    "\n",
    "This notebook lets you edit locally in VS Code while executing on a Google Colab runtime via a secure tunnel, and also provides robust loading/cleaning for `Grocery_Inventory_new_v1.csv`.\n",
    "\n",
    "COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    COLAB = True\n",
    "except Exception:\n",
    "    COLAB = False\n",
    "print(f\"Running in Colab: {COLAB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872401bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and Import Dependencies\n",
    "\n",
    "If running on Colab, we'll install required packages. Locally in VS Code, you can skip this cell and use your own environment.\n",
    "\n",
    "import sys, os, subprocess, textwrap, random, string, json, time, io, re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Minimal set here; the repo's requirements.txt will be installed if in Colab.\n",
    "if 'google.colab' in sys.modules:\n",
    "    %pip -q install --upgrade pip\n",
    "    %pip -q install pandas pyarrow numpy seaborn matplotlib cloudflared jinja2\n",
    "    # Also install project requirements if present\n",
    "    REPO_URL = 'https://github.com/piumalnipun9/Inventory-Management-Forecasting-using-Machine-Learning.git'\n",
    "    WORKDIR = '/content/Inventory-Management-Forecasting-using-Machine-Learning'\n",
    "    if not os.path.exists(WORKDIR):\n",
    "        !git clone --depth=1 $REPO_URL $WORKDIR\n",
    "    else:\n",
    "        %cd $WORKDIR\n",
    "        !git pull --rebase --autostash\n",
    "        %cd -\n",
    "    REQ = os.path.join(WORKDIR, 'requirements.txt')\n",
    "    if os.path.exists(REQ):\n",
    "        %pip -q install -r $REQ\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "print('Dependencies ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive Auth/Mount (Colab) and Local/Upload Fallback\n",
    "\n",
    "If on Colab, we can mount Drive and also support file upload for `Grocery_Inventory_new_v1.csv`.\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "UPLOADS = {}\n",
    "DRIVE_MOUNT = '/content/drive'\n",
    "if COLAB:\n",
    "    try:\n",
    "        from google.colab import drive, files  # type: ignore\n",
    "        drive.mount(DRIVE_MOUNT, force_remount=False)\n",
    "    except Exception as e:\n",
    "        print('Drive mount skipped:', e)\n",
    "    try:\n",
    "        print('If your CSV is not on Drive, use the uploader below to select it from your computer...')\n",
    "        UPLOADS = files.upload()  # opens a dialog in Colab UI\n",
    "        print('Uploaded files:', list(UPLOADS.keys()))\n",
    "    except Exception as e:\n",
    "        print('Upload dialog not available or canceled:', e)\n",
    "else:\n",
    "    print('Running outside Colab; Drive mount and uploader are skipped.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust CSV Loader for Grocery_Inventory_new_v1.csv\n",
    "\n",
    "This will try these paths in order: local Windows path, Drive path, or uploaded file.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def load_csv() -> Path | None:\n",
    "    candidates = []\n",
    "    # 1) Local Windows path as provided in VS Code workspace\n",
    "    candidates.append(Path(r\"e:/Web Development/Inventory_Manager/Grocery_Inventory_new_v1.csv\"))\n",
    "    candidates.append(Path(r\"E:/Web Development/Inventory_Manager/Grocery_Inventory_new_v1.csv\"))\n",
    "    # 2) If running in Colab and Drive is mounted, look under MyDrive common locations\n",
    "    if COLAB:\n",
    "        drive_candidates = [\n",
    "            Path(DRIVE_MOUNT) / 'MyDrive' / 'Grocery_Inventory_new_v1.csv',\n",
    "            Path(DRIVE_MOUNT) / 'MyDrive' / 'Inventory' / 'Grocery_Inventory_new_v1.csv',\n",
    "        ]\n",
    "        candidates.extend(drive_candidates)\n",
    "    # 3) Uploaded file in Colab\n",
    "    if COLAB and UPLOADS:\n",
    "        for name in UPLOADS.keys():\n",
    "            if name.lower() == 'grocery_inventory_new_v1.csv':\n",
    "                # Save uploaded content to the current working directory\n",
    "                open(name, 'wb').write(UPLOADS[name])\n",
    "                candidates.insert(0, Path(name))\n",
    "                break\n",
    "    for p in candidates:\n",
    "        try:\n",
    "            if p.exists():\n",
    "                # Probe readable\n",
    "                _df = pd.read_csv(p, engine='python', dtype=str, nrows=5)\n",
    "                print('Found CSV at:', p)\n",
    "                return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    print('CSV not found. Please ensure the file exists in one of the probed paths or upload via the widget.')\n",
    "    return None\n",
    "\n",
    "CSV_PATH = load_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Utilities\n",
    "\n",
    "# Helpers to normalize and parse fields\n",
    "\n",
    "import math\n",
    "\n",
    "def rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = {c: c.strip() for c in df.columns}\n",
    "    df = df.rename(columns=cols)\n",
    "    if 'Catagory' in df.columns and 'Category' not in df.columns:\n",
    "        df = df.rename(columns={'Catagory': 'Category'})\n",
    "    return df\n",
    "\n",
    "def to_money(x) -> float:\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return 0.0\n",
    "    s = str(x).strip().replace('$','').replace(',','')\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def to_percent(x) -> float:\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return 0.0\n",
    "    s = str(x).strip().replace('%','')\n",
    "    # handle cases like '089', '-161', '001'\n",
    "    s = re.sub(r'[^0-9\\-\\.]+', '', s)\n",
    "    if s == '' or s == '-' or s == '.':\n",
    "        return 0.0\n",
    "    try:\n",
    "        v = float(s) / 100.0\n",
    "        # sanity clip to [-3, 3]\n",
    "        return max(-3.0, min(3.0, v))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def to_int_safe(x) -> int:\n",
    "    try:\n",
    "        return int(float(str(x).strip()))\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def to_date_safe(x):\n",
    "    if x is None:\n",
    "        return pd.NaT\n",
    "    s = str(x).strip()\n",
    "    for fmt in ['%m/%d/%Y', '%Y-%m-%d', '%d/%m/%Y']:\n",
    "        try:\n",
    "            return pd.to_datetime(s, format=fmt, errors='raise')\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.to_datetime(s, errors='coerce')\n",
    "\n",
    "raw_df = None\n",
    "if CSV_PATH is not None:\n",
    "    raw_df = pd.read_csv(CSV_PATH, engine='python', dtype=str)\n",
    "    raw_df = rename_columns(raw_df)\n",
    "    # Parse and normalize key columns\n",
    "    for col in ['Unit_Price']:\n",
    "        if col in raw_df.columns:\n",
    "            raw_df[col] = raw_df[col].map(to_money)\n",
    "    if 'percentage' in raw_df.columns:\n",
    "        raw_df['percentage'] = raw_df['percentage'].map(to_percent)\n",
    "    for col in ['Stock_Quantity','Reorder_Level','Reorder_Quantity','Sales_Volume','Inventory_Turnover_Rate']:\n",
    "        if col in raw_df.columns:\n",
    "            raw_df[col] = raw_df[col].map(to_int_safe)\n",
    "    for col in ['Date_Received','Last_Order_Date','Expiration_Date']:\n",
    "        if col in raw_df.columns:\n",
    "            raw_df[col] = raw_df[col].map(to_date_safe)\n",
    "\n",
    "print('Cleaning complete' if raw_df is not None else 'No CSV loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e66adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation and Fixups\n",
    "\n",
    "changes = {}\n",
    "if raw_df is not None:\n",
    "    df = raw_df.copy()\n",
    "    # Fill missing Category from Product_Name heuristics\n",
    "    if 'Category' in df.columns and 'Product_Name' in df.columns:\n",
    "        mask_blank = df['Category'].isna() | (df['Category'].astype(str).str.strip() == '')\n",
    "        inferred = df.loc[mask_blank, 'Product_Name'].astype(str).str.lower().map({\n",
    "            'milk': 'Dairy', 'cheese': 'Dairy', 'yogurt': 'Dairy',\n",
    "            'apple': 'Produce', 'banana': 'Produce', 'carrot': 'Produce',\n",
    "            'bread': 'Bakery', 'cake': 'Bakery'\n",
    "        }).fillna('Grocery')\n",
    "        before = mask_blank.sum()\n",
    "        df.loc[mask_blank, 'Category'] = inferred\n",
    "        after = df['Category'].isna().sum()\n",
    "        changes['filled_category'] = int(before - after)\n",
    "    # Clip percentage\n",
    "    if 'percentage' in df.columns:\n",
    "        before = df['percentage'].copy()\n",
    "        df['percentage'] = df['percentage'].clip(-3.0, 3.0)\n",
    "        changes['percentage_clipped'] = int((before != df['percentage']).sum())\n",
    "    # Drop negative quantities\n",
    "    for col in ['Stock_Quantity','Reorder_Level','Reorder_Quantity','Sales_Volume']:\n",
    "        if col in df.columns:\n",
    "            neg = (df[col] < 0).sum()\n",
    "            if neg > 0:\n",
    "                df.loc[df[col] < 0, col] = 0\n",
    "                changes[f'neg_{col}_to_zero'] = int(neg)\n",
    "    # Normalize Status\n",
    "    if 'Status' in df.columns:\n",
    "        mapping = {'active':'Active','backordered':'Backordered','discontinued':'Discontinued'}\n",
    "        df['Status'] = df['Status'].astype(str).str.strip().str.lower().map(mapping).fillna('Active')\n",
    "        changes['status_normalized'] = int(len(df))\n",
    "else:\n",
    "    df = None\n",
    "\n",
    "print('Validation complete. Changes:', changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA Checks and Queries\n",
    "\n",
    "if df is not None:\n",
    "    display(df.info())\n",
    "    display(df.head(10))\n",
    "    if 'Stock_Quantity' in df.columns:\n",
    "        display(df.sort_values('Stock_Quantity', ascending=False).head(10))\n",
    "    if set(['Stock_Quantity','Reorder_Level']).issubset(df.columns):\n",
    "        low = df[df['Stock_Quantity'] <= df['Reorder_Level']]\n",
    "        print('Items at/below reorder level:', len(low))\n",
    "        display(low.head(10))\n",
    "    if 'Expiration_Date' in df.columns:\n",
    "        soon = df[df['Expiration_Date'] <= (pd.Timestamp.today() + pd.Timedelta(days=30))]\n",
    "        print('Expiring within 30 days:', len(soon))\n",
    "        display(soon.head(10))\n",
    "    if set(['Category','Unit_Price']).issubset(df.columns):\n",
    "        display(df.groupby('Category')['Unit_Price'].mean().sort_values(ascending=False).head(10))\n",
    "    # Optional simple plot\n",
    "    if set(['Category','Stock_Quantity']).issubset(df.columns):\n",
    "        sns.barplot(x='Category', y='Stock_Quantity', data=df)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.title('Stock by Category')\n",
    "        plt.show()\n",
    "else:\n",
    "    print('No data loaded for EDA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3132da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Cleaned Data (CSV/Parquet)\n",
    "\n",
    "output_dir = 'cleaned'\n",
    "if df is not None:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    csv_out = os.path.join(output_dir, f'Grocery_Inventory_cleaned_{ts}.csv')\n",
    "    pq_out = os.path.join(output_dir, f'Grocery_Inventory_cleaned_{ts}.parquet')\n",
    "    df.to_csv(csv_out, index=False)\n",
    "    try:\n",
    "        df.to_parquet(pq_out, index=False)\n",
    "        print('Saved:', csv_out, 'and', pq_out)\n",
    "    except Exception as e:\n",
    "        print('Parquet save skipped:', e)\n",
    "else:\n",
    "    print('No cleaned data to save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20290e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Project Conversion and Pipeline in Colab\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    WORKDIR = '/content/Inventory-Management-Forecasting-using-Machine-Learning'\n",
    "    %cd $WORKDIR\n",
    "\n",
    "# Write the uploaded/loaded CSV to repo root if not already\n",
    "if CSV_PATH is not None:\n",
    "    target = Path('Grocery_Inventory_new_v1.csv')\n",
    "    if not target.exists() or Path(CSV_PATH).resolve() != target.resolve():\n",
    "        try:\n",
    "            tmp_df = pd.read_csv(CSV_PATH, engine='python')\n",
    "            tmp_df.to_csv(target, index=False)\n",
    "            print('Copied CSV into repo root for scripts:', target)\n",
    "        except Exception as e:\n",
    "            print('Copy skipped:', e)\n",
    "else:\n",
    "    print('CSV not available; you can still run with synthetic data by setting --generate-synthetic')\n",
    "\n",
    "# Conversion\n",
    "if Path('Grocery_Inventory_new_v1.csv').exists():\n",
    "    !python -m scripts.convert_grocery_csv --input \"Grocery_Inventory_new_v1.csv\" --out-dir data --lead-time 7\n",
    "else:\n",
    "    print('Skipping conversion; no CSV found in repo root')\n",
    "\n",
    "# Choose model\n",
    "USE_PROPHET = False  # set True to use Prophet (slower, better forecasts)\n",
    "model_name = 'prophet' if USE_PROPHET else 'lstm_stub'\n",
    "\n",
    "# Run pipeline\n",
    "!python -m scripts.train_and_update --data-dir data --output-dir outputs --model $model_name --horizon 30 --plot-examples 3\n",
    "\n",
    "# Return to the parent if we changed directory\n",
    "if 'google.colab' in sys.modules:\n",
    "    %cd -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caabae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Key Outputs\n",
    "\n",
    "import glob\n",
    "from IPython.display import display\n",
    "\n",
    "reco = Path('outputs/reorder_recommendations.csv')\n",
    "if reco.exists():\n",
    "    df_reco = pd.read_csv(reco)\n",
    "    display(df_reco.head(20))\n",
    "else:\n",
    "    print('No reorder_recommendations.csv found yet')\n",
    "\n",
    "plots_dir = Path('outputs/plots')\n",
    "if plots_dir.exists():\n",
    "    pngs = sorted(glob.glob(str(plots_dir / '*.png')))\n",
    "    print(f'Found {len(pngs)} plots')\n",
    "    for p in pngs[:5]:\n",
    "        display(p)\n",
    "else:\n",
    "    print('No plots directory found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Latest Code From GitHub (for VS Code ↔ Colab loop)\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    WORKDIR = '/content/Inventory-Management-Forecasting-using-Machine-Learning'\n",
    "    %cd $WORKDIR\n",
    "    !git pull --rebase --autostash\n",
    "    %cd -\n",
    "else:\n",
    "    print('Not in Colab; git pull not needed here')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Remote Jupyter Server in Colab + Secure Tunnel for VS Code\n",
    "\n",
    "This will start a Jupyter Server on port 9000 and expose it via Cloudflared.\n",
    "\n",
    "import secrets\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Install cloudflared if missing (already installed earlier, but ensure again)\n",
    "    %pip -q install cloudflared > /dev/null\n",
    "    # Random token\n",
    "    TOKEN = secrets.token_hex(16)\n",
    "    PORT = 9000\n",
    "    print('Starting Jupyter Server on port', PORT)\n",
    "    server_cmd = f\"jupyter server --ServerApp.token={TOKEN} --ServerApp.allow_origin='*' --no-browser --port={PORT} --NotebookApp.allow_origin='*' --ServerApp.allow_remote_access=True\"\n",
    "    server_proc = subprocess.Popen(shlex.split(server_cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    time.sleep(3)\n",
    "    print('Starting Cloudflared tunnel...')\n",
    "    tunnel_proc = subprocess.Popen(['cloudflared', 'tunnel', '--url', f'http://localhost:{PORT}', '--no-autoupdate'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    public_url = None\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < 60 and public_url is None:\n",
    "        line = tunnel_proc.stdout.readline().strip() if tunnel_proc.stdout else ''\n",
    "        if line:\n",
    "            print(line)\n",
    "        m = re.search(r'https:\\/\\/[-a-z0-9]+\\.trycloudflare\\.com', line)\n",
    "        if m:\n",
    "            public_url = m.group(0)\n",
    "            break\n",
    "    if public_url:\n",
    "        print('Public URL:', public_url)\n",
    "        print('Token:', TOKEN)\n",
    "    else:\n",
    "        print('Failed to retrieve public URL; check tunnel logs above')\n",
    "else:\n",
    "    print('Not running in Colab; skip remote server')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1919d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print VS Code Jupyter Server URI and Token\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    try:\n",
    "        uri = f\"{public_url}?token={TOKEN}\" if 'public_url' in globals() and public_url else None\n",
    "        if uri:\n",
    "            print('Copy this into VS Code:')\n",
    "            print('Jupyter Server URI:', uri)\n",
    "            print('Or paste public URL into the Jupyter: Specify Jupyter Server dialog.')\n",
    "        else:\n",
    "            print('Public URL not available; please re-run the previous cell to establish the tunnel.')\n",
    "    except Exception as e:\n",
    "        print('Error printing URI:', e)\n",
    "else:\n",
    "    print('Not in Colab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862799d",
   "metadata": {},
   "source": [
    "# VS Code Usage Instructions\n",
    "\n",
    "1. In VS Code, open your local repository folder.\n",
    "2. Install the Jupyter extension if you haven't.\n",
    "3. Command Palette → \"Jupyter: Specify Jupyter Server for connections\" → \"Existing\".\n",
    "4. Paste the URI printed above (it ends with trycloudflare.com and includes ?token=...).\n",
    "5. Open any local .ipynb and run cells; execution will happen on the Colab kernel.\n",
    "6. Edit Python files locally; commit/push. In this notebook, run the \"Pull Latest Code\" cell to sync.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ee3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Lightweight Tests for Cleaning Functions\n",
    "\n",
    "def _assert(name, cond):\n",
    "    if not cond:\n",
    "        raise AssertionError(f'Test failed: {name}')\n",
    "    print('PASS', name)\n",
    "\n",
    "# Tests\n",
    "_assert('to_money $53.82', abs(to_money('$53.82') - 53.82) < 1e-6)\n",
    "_assert('to_percent 089%', abs(to_percent('089%') - 0.89) < 1e-6)\n",
    "_assert('to_percent -033%', abs(to_percent('-033%') + 0.33) < 1e-6)\n",
    "_assert('to_date_safe 1/2/2025', str(to_date_safe('1/2/2025').date()) == '2025-01-02')\n",
    "print('All cleaning tests passed')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
